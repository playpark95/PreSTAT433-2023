{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/playpark95/Others-at-KoreaUniv/blob/main/KU_%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%8A%A4%ED%84%B0%EB%94%94_4%EC%A3%BC%EC%B0%A8_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-MdljjMe6yh",
        "outputId": "c8c44028-9b4a-4731-e483-dcc461a3b331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KU-pytorch-study-2023'...\n",
            "remote: Enumerating objects: 154, done.\u001b[K\n",
            "remote: Counting objects: 100% (101/101), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 154 (delta 67), reused 92 (delta 60), pack-reused 53\u001b[K\n",
            "Receiving objects: 100% (154/154), 60.06 MiB | 11.49 MiB/s, done.\n",
            "Resolving deltas: 100% (89/89), done.\n",
            "Updating files: 100% (14/14), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/sungbinlim/KU-pytorch-study-2023.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ../content/KU-pytorch-study-2023/ion_data/train.zip -d ../content/KU-pytorch-study-2023/ion_data/\n",
        "!unzip ../content/KU-pytorch-study-2023/ion_data/valid.zip -d ../content/KU-pytorch-study-2023/ion_data/\n",
        "!rm -r -f ../content/KU-pytorch-study-2023/ion_data/__MACOSX/"
      ],
      "metadata": {
        "id": "RN7CPBGPwFxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import transforms as T\n",
        "import pandas as pd\n",
        "from PIL import Image # Bytes 로 압축된 이미지를 이미지로 변환하기 위해 필요\n",
        "\n",
        "class IonDataset(Dataset):\n",
        "    def __init__(self, data_dir, mode='train', img_size=(10, 300), n=None):\n",
        "        self.df = pd.read_pickle(os.path.join(data_dir, f\"{mode}.pkl\"))\n",
        "\n",
        "        if n is not None:\n",
        "            self.df = self.df[self.df['n'] == n]\n",
        "        self.data_dir = data_dir\n",
        "        self.image_path = self.df['img_path'].values\n",
        "\n",
        "        # min-max normalization\n",
        "        self.min_a2 = 0.146\n",
        "        self.max_a2 = 0.522\n",
        "        self.df[\"norm_potential\"] = self.df[\"potential\"].apply(lambda p : (p - self.min_a2) / (self.max_a2 - self.min_a2))\n",
        "\n",
        "        self.n = self.df[\"n\"].values\n",
        "        self.max_n = self.n.max()\n",
        "        self.min_n = self.n.min()\n",
        "\n",
        "        self.potential = self.df['potential'].values.astype('float32')\n",
        "        self.norm_potential = self.df['norm_potential'].values.astype('float32')\n",
        "        self.position = self.df['position'].values\n",
        "\n",
        "        self.h, self.w = img_size\n",
        "\n",
        "        self.img_transform = T.Compose([T.ToTensor(),\n",
        "        ])\n",
        "\n",
        "    def make_one_hot(self, scalar):\n",
        "        one_hot_dim = self.max_n - self.min_n + 1\n",
        "        address = scalar - one_hot_dim - 1\n",
        "        one_hot_vec = np.zeros(one_hot_dim)\n",
        "        one_hot_vec[address] = 1.0\n",
        "        return one_hot_vec\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img = Image.open(os.path.join(self.data_dir, self.image_path[idx]))\n",
        "        img = self.img_transform(img)\n",
        "        ion_number = torch.tensor(self.make_one_hot(self.n[idx]))\n",
        "        ion_potential = torch.tensor(self.norm_potential[idx])\n",
        "\n",
        "        return img, ion_number, ion_potential"
      ],
      "metadata": {
        "id": "fFoJ4jmoHvqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "oYdUn-5KMrkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, hidden_variables=[128, 64], input_output_dim=(1, 1)):\n",
        "        super().__init__()\n",
        "        self.input_variable_dim = input_output_dim[0]\n",
        "        self.output_variable_dim = input_output_dim[1]\n",
        "        self.list_hidden_variable = hidden_variables\n",
        "        self.layer = nn.Sequential()\n",
        "\n",
        "        variable_dim = self.input_variable_dim\n",
        "        for i, hidden_variable in enumerate(self.list_hidden_variable):\n",
        "            self.layer.add_module('layer_' + str(i), nn.Linear(variable_dim, hidden_variable, dtype=torch.float32))\n",
        "            self.layer.add_module('activation_' + str(i), nn.ReLU())\n",
        "            variable_dim = hidden_variable\n",
        "        self.layer.add_module('final_layer', nn.Linear(variable_dim, self.output_variable_dim, dtype=torch.float32))\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_hat = self.layer(x)\n",
        "        return y_hat\n",
        "\n",
        "class IonPredictor(nn.Module):\n",
        "    def __init__(self, kernel_size=3, num_features=1000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cnn = models.resnet18()\n",
        "        self.cnn.conv1 = nn.Conv2d(1, 64, kernel_size=kernel_size, stride=2, padding=3, bias=False)\n",
        "        self.mlp = MLP(input_output_dim=(num_features, 5))\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        z = self.cnn(x)\n",
        "        z.view(z.size(0), -1)\n",
        "        predict = self.mlp(z)\n",
        "        return predict[:, :4], predict[:, 4]"
      ],
      "metadata": {
        "id": "2vvD28YCMxMr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}