{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"5AEVdl-sMTvd","executionInfo":{"status":"ok","timestamp":1685955475731,"user_tz":-540,"elapsed":4467,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import time"]},{"cell_type":"markdown","metadata":{"id":"09dejfNpsXwD"},"source":["# Numpy linalgebra basic functions\n","\n","아래와 같은 기본적인 linear algebra 함수들의 사용법을 알아보겠습니다.\n","\n","### Matrix and vector products\n","*   Rank\n","*   Trace\n","*   Determinant\n","*   Inverse\n","*   Power\n","*   Eigenvalue\n","*   Norm\n","*   Singular Value Decomposition  \n"]},{"cell_type":"markdown","metadata":{"id":"0EogXFcGvCaY"},"source":["예제에 사용할 random array를 만듭니다."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1685955475731,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"},"user_tz":-540},"id":"1PKWhOlN5Isv","outputId":"7bfac2a8-fc23-4f09-caca-71d4ccb2cdb6"},"outputs":[{"output_type":"stream","name":"stdout","text":["X: \n","[[0.3787661  0.32064462 0.10324807]\n"," [0.12700387 0.98621645 0.68072946]\n"," [0.51770779 0.69754444 0.06783047]] \n"," X2: \n","[[0.5336999  0.3653256  0.28804943]\n"," [0.29091874 0.74885801 0.93731009]\n"," [0.60591132 0.76748547 0.31153618]]\n"]}],"source":["X = np.random.rand(3, 3)\n","X2 = np.random.rand(3, 3)\n","\n","print(f\"X: \\n{X} \\n X2: \\n{X2}\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1685955475732,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"},"user_tz":-540},"id":"K1l1plAhMx_v","outputId":"60676e20-5080-460c-e24a-f5f76bfbd953"},"outputs":[{"output_type":"stream","name":"stdout","text":["Rank of X: 3\n"]}],"source":["# Rank of a matrix\n","print(\"Rank of X:\", np.linalg.matrix_rank(X))"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1685955475732,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"},"user_tz":-540},"id":"XwpKFc-M52zj","outputId":"c0c94f39-a466-4c62-90a8-a406e7b4df94"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Trace of X: 1.4328130292241563\n"]}],"source":["# Trace of matrix\n","print(\"\\nTrace of X:\", np.trace(X))"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1685955475732,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"},"user_tz":-540},"id":"1NxnGo4d54dM","outputId":"075f50dc-bc50-4dad-de0a-12e5d41b1b5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Dot product of X, X2: [[0.35798813 0.45773163 0.4418123 ]\n"," [0.76715249 1.30738382 1.17304588]\n"," [0.5203286  0.76355255 0.82407252]]\n"]}],"source":["# Dot product of matrice\n","print(\"\\nDot product of X, X2:\", np.dot(X, X2))"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1685955475732,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"},"user_tz":-540},"id":"UcgM7IDl55jK","outputId":"ca370263-44c9-43e9-e739-03affe1d31d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Matmul of X, X2: [[0.35798813 0.45773163 0.4418123 ]\n"," [0.76715249 1.30738382 1.17304588]\n"," [0.5203286  0.76355255 0.82407252]]\n"]}],"source":["# Matmul of matrice\n","print(\"\\nMatmul of X, X2:\", np.matmul(X, X2))"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1685955475732,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"},"user_tz":-540},"id":"2ur_KmIt56zv","outputId":"a12e9c0e-2694-4454-d01e-be14a79f838d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Determinant of X: -0.08784493956970786\n"]}],"source":["# Determinant of a matrix\n","print(\"\\nDeterminant of X:\", np.linalg.det(X))"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1685955475732,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"},"user_tz":-540},"id":"MhaR9JB9574u","outputId":"e814eb0e-1971-45ad-e4e3-cd79f41db557"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Inverse of X:\n"," [[ 4.64390456 -0.57226562 -1.32560046]\n"," [-3.91376224  0.31601643  2.78586723]\n"," [ 4.80370411  1.11794683 -3.78874705]]\n","X @ X^-1 :\n"," [[ 1.00000000e+00  1.70172188e-17  2.42208124e-16]\n"," [ 1.83371008e-16  1.00000000e+00  4.58467429e-17]\n"," [-1.50625137e-16 -4.40241099e-18  1.00000000e+00]]\n"]}],"source":["# Inverse of matrix X\n","print(\"\\nInverse of X:\\n\", np.linalg.inv(X))\n","\n","identity = np.matmul(X, np.linalg.inv(X))\n","print(f\"X @ X^-1 :\\n\", identity)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1685955475732,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"},"user_tz":-540},"id":"22E_EnDJ59QQ","outputId":"c3412de2-0d13-4684-a7b2-48aea84de80a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Matrix X raised to power 3:\n"," [[0.2916157  0.76328527 0.38943298]\n"," [0.76640651 2.14590961 1.11689609]\n"," [0.51147249 1.36307983 0.68266867]]\n"]}],"source":["\n","# Power of matrix X\n","print(\"\\nMatrix X raised to power 3:\\n\",\n","           np.linalg.matrix_power(X, 3))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1685955475732,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"},"user_tz":-540},"id":"Wprekf3w5-Wy","outputId":"eced326d-3a6b-48ec-81f7-c6d2cb4e6cc9"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Eigenvalue of X are:\n"," (array([-0.26018929,  0.23091619,  1.46208612]), array([[-0.10296105, -0.77966451, -0.28830347],\n","       [ 0.48483822,  0.48646945, -0.80921966],\n","       [-0.86852226, -0.39429775, -0.51190298]]))\n"]}],"source":["# Eigenvalue of matrix X\n","print(\"\\nEigenvalue of X are:\\n\",\n","      np.linalg.eig(X))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1685955475732,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"},"user_tz":-540},"id":"PNKIngyv5_iL","outputId":"4198cd4f-2970-42f1-bb6c-119cbd9d2056"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Eigenvalue of X are:\n"," [0.50688943 1.20504999 0.87131542]\n"]}],"source":["# Norm of matrix X\n","print(\"\\Norm of X are:\\n\",\n","      np.linalg.norm(X, axis=-1))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1685955475732,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"},"user_tz":-540},"id":"kCZadIpE6ApC","outputId":"ce13d765-f5d1-4c3d-af0f-4cd92d545bd1"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Singular Value Decomposition of X are:\n"," (array([[-0.29981116,  0.42854301, -0.85232867],\n","       [-0.78723723, -0.6157829 , -0.03269507],\n","       [-0.53886066,  0.66118251,  0.5219836 ]]), array([1.47144862, 0.53931285, 0.11069573]), array([[-0.3347129 , -0.84841454, -0.41007322],\n","       [ 0.79065442, -0.01609648, -0.61205106],\n","       [-0.51267228,  0.52908759, -0.6761904 ]]))\n"]}],"source":["# Singular Value Decomposition of matrix X\n","u, k, v = np.linalg.svd(X)\n","print(\"\\nSingular Value Decomposition of X are:\\n\",\n","      np.linalg.svd(X))"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1685955475732,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"},"user_tz":-540},"id":"kUK_N6p57p6K","outputId":"1e636813-767a-46bf-92bc-937166f39220"},"outputs":[{"output_type":"stream","name":"stdout","text":["u @ u^T:\n"," [[ 1.00000000e+00 -2.70162777e-16 -9.66423797e-17]\n"," [-2.70162777e-16  1.00000000e+00 -1.88225868e-16]\n"," [-9.66423797e-17 -1.88225868e-16  1.00000000e+00]]\n","v @ v^T:\n"," [[ 1.00000000e+00  1.35699650e-17 -1.54947844e-16]\n"," [ 1.35699650e-17  1.00000000e+00  9.47348854e-17]\n"," [-1.54947844e-16  9.47348854e-17  1.00000000e+00]]\n","check whether svd is correct or not: \n"," [[ True  True  True]\n"," [ True  True  True]\n"," [ True  True  True]]\n"]}],"source":["print(\"u @ u^T:\\n\", np.matmul(u, u.T))\n","print(\"v @ v^T:\\n\", np.matmul(v, v.T))\n","check = u@np.diag(k)@v - X\n","print(\"check whether svd is correct or not: \\n\", np.where(check < pow(1, -10), True, False))"]},{"cell_type":"markdown","source":["위 내용들을 torch library를 사용해서 수행해보겠습니다."],"metadata":{"id":"OUigPimtyIr3"}},{"cell_type":"code","source":["X = torch.rand(3, 3)\n","X2 = torch.rand(3, 3)"],"metadata":{"id":"vLfGP2vZyIGE","executionInfo":{"status":"ok","timestamp":1685955641492,"user_tz":-540,"elapsed":587,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# Rank of a matrix\n","print(\"Rank of X:\", torch.linalg.matrix_rank(X))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sDGotJTNyYiw","executionInfo":{"status":"ok","timestamp":1685955650273,"user_tz":-540,"elapsed":5,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"}},"outputId":"048696cc-bd9f-4fe0-a2d2-d741bd95c00b"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Rank of X: tensor(3)\n"]}]},{"cell_type":"code","source":["# Trace of matrix\n","print(\"\\nTrace of X:\", torch.trace(X))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZWGCCiAXydcE","executionInfo":{"status":"ok","timestamp":1685955668715,"user_tz":-540,"elapsed":3,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"}},"outputId":"2fd898c3-9a8e-40ea-b5b8-bd5ae72f17a1"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Trace of X: tensor(0.8201)\n"]}]},{"cell_type":"code","source":["# Dot product of matrice\n","print(\"\\nDot product of X, X2:\", torch.dot(X[0], X2[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sSSSo0neyhAN","executionInfo":{"status":"ok","timestamp":1685955750667,"user_tz":-540,"elapsed":569,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"}},"outputId":"4e184048-5b79-42e2-d521-9b303c4f21eb"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Dot product of X, X2: tensor(0.0901)\n"]}]},{"cell_type":"code","source":["# Matmul of matrice\n","print(\"\\nMatmul of X, X2:\", torch.matmul(X, X2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yR9MKaydykFF","executionInfo":{"status":"ok","timestamp":1685955756246,"user_tz":-540,"elapsed":3,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"}},"outputId":"ea5bd680-5263-44ac-caf3-1b26404adc86"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Matmul of X, X2: tensor([[0.0972, 0.6361, 0.3070],\n","        [0.1450, 1.0986, 0.3721],\n","        [0.1250, 0.8109, 0.2408]])\n"]}]},{"cell_type":"code","source":["# Determinant of a matrix\n","print(\"\\nDeterminant of X:\", torch.linalg.det(X))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k9nX7te-y3r-","executionInfo":{"status":"ok","timestamp":1685955777070,"user_tz":-540,"elapsed":4,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"}},"outputId":"0c3ffd82-c35b-4d7d-92ca-89ee5d6a0dd5"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Determinant of X: tensor(-0.1084)\n"]}]},{"cell_type":"code","source":["# Inverse of matrix X\n","print(\"\\nInverse of X:\\n\", torch.linalg.inv(X))\n","\n","identity = torch.matmul(X, torch.linalg.inv(X))\n","print(f\"X @ X^-1 :\\n\", identity)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N4gHy2QHy8hq","executionInfo":{"status":"ok","timestamp":1685955803684,"user_tz":-540,"elapsed":3,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"}},"outputId":"6206adf7-01b0-468a-fce7-c5c8dfd246c7"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Inverse of X:\n"," tensor([[-0.5753, -0.6317,  1.8640],\n","        [ 0.0906,  3.8057, -4.2118],\n","        [ 2.1698, -0.9948,  0.8669]])\n","X @ X^-1 :\n"," tensor([[ 1.0000e+00, -5.9605e-08,  8.9407e-08],\n","        [ 0.0000e+00,  1.0000e+00,  1.0431e-07],\n","        [ 5.9605e-08,  5.9605e-08,  1.0000e+00]])\n"]}]},{"cell_type":"code","source":["# Power of matrix X\n","print(\"\\nMatrix X raised to power 3:\\n\",\n","           torch.linalg.matrix_power(X, 3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1uwQaoHpzDBl","executionInfo":{"status":"ok","timestamp":1685955823454,"user_tz":-540,"elapsed":2,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"}},"outputId":"3cd26706-0e2a-46d0-ecf0-a15eee21a03a"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Matrix X raised to power 3:\n"," tensor([[0.4148, 0.2143, 0.3710],\n","        [1.1078, 0.4675, 0.6473],\n","        [0.8177, 0.3236, 0.4369]])\n"]}]},{"cell_type":"code","source":["# Singular Value Decomposition of matrix X\n","u, k, v = torch.linalg.svd(X)\n","print(\"\\nSingular Value Decomposition of X are:\\n\",\n","      torch.linalg.svd(X))"],"metadata":{"id":"-ya5fLmKzsWd","executionInfo":{"status":"ok","timestamp":1685955995803,"user_tz":-540,"elapsed":3,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"}},"outputId":"15bb29cb-4798-4f5d-be8c-6098aa495273","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Singular Value Decomposition of X are:\n"," torch.return_types.linalg_svd(\n","U=tensor([[-0.1794,  0.9830,  0.0391],\n","        [-0.7552, -0.1121, -0.6458],\n","        [-0.6305, -0.1454,  0.7625]]),\n","S=tensor([1.5021, 0.4407, 0.1638]),\n","Vh=tensor([[-0.8936, -0.3529, -0.2772],\n","        [-0.3375,  0.1211,  0.9335],\n","        [ 0.2958, -0.9278,  0.2273]]))\n"]}]},{"cell_type":"markdown","metadata":{"id":"AI0gMo1ZXc5I"},"source":["# Parallel computation using numpy - How to substitute for loop"]},{"cell_type":"markdown","metadata":{"id":"xZqeA2LR7BjY"},"source":["multi dimensional array 계산을 할 때, 단순히 `for loop`를 사용할 경우 for loop의 길이만큼 computational cost가 증가합니다.\n","\n","하지만 `numpy`는 `C`로 작성된 함수를 사용해 multi dimensional array를 계산하기 때문에, for loop에 비해 훨씬 좋은 계산 효율을 보여줍니다.\n","\n","예제를 통해 알아보겠습니다."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"MpWvZS3_Z2ZT","executionInfo":{"status":"ok","timestamp":1685955475732,"user_tz":-540,"elapsed":6,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"}}},"outputs":[],"source":["array1 = np.random.rand(100)"]},{"cell_type":"markdown","metadata":{"id":"iCXGe31-fN35"},"source":["\n","주어진 array의 원소들을 절댓값으로 수정하여 반환하는 함수를 사용하여,\n","\n","`numpy`와 `for loop` 사용 시의 computational time을 비교하겠습니다."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"umesvlYYXkVU","executionInfo":{"status":"ok","timestamp":1685955475732,"user_tz":-540,"elapsed":5,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"}}},"outputs":[],"source":["# python decorator to record function execution time\n","def timer(func):\n","    def wrapper(*args, **kwargs):\n","        start_time = time.time()\n","        result = func(*args, **kwargs)\n","        end_time = time.time()\n","        computation_time = end_time - start_time\n","        print(f\"Execution time of {func.__name__}: {computation_time} seconds\")\n","        return computation_time\n","    return wrapper\n","\n","@timer\n","def take_abs_using_for_loop(array):\n","  for i in range(len(array)):\n","    array[i] = np.abs(array[i])\n","  return array\n","\n","@timer\n","def take_abs_using_parallelism(array):\n","  return np.abs(array)"]},{"cell_type":"markdown","metadata":{"id":"86mNqVwE7BjZ"},"source":["`timer` 는 함수의 실행시간을 측정하기 위해 작성된 `decorator`입니다."]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1685955475733,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"},"user_tz":-540},"id":"74EuebPFaRP3","outputId":"e6cae87e-2653-4b72-9766-ad7498bdc006"},"outputs":[{"output_type":"stream","name":"stdout","text":["Execution time of take_abs_using_for_loop: 0.00022935867309570312 seconds\n","Execution time of take_abs_using_parallelism: 5.4836273193359375e-06 seconds\n"]}],"source":["time1 = take_abs_using_for_loop(array1)\n","time2 = take_abs_using_parallelism(array1)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1685955475733,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"},"user_tz":-540},"id":"5Vo_m3Bv7Bja","outputId":"f910c5cc-8cde-40fe-c012-baa0e4a3b5bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["computation using parallelism is 41.82608695652174 times faster than for loop.\n"]}],"source":["print(f\"computation using parallelism is {time1 / time2} times faster than for loop.\")"]},{"cell_type":"markdown","metadata":{"id":"6cNL7SKwwggA"},"source":["위의 multi dimensional array 예제에서, for loop를 사용한 경우보다 numpy를 사용한 경우가 26.75배 빠른 것을 알 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"ri_v8XOJarad"},"source":["# torch tensor 소개\n","\n","torch tensor는 numpy와 비슷하게, C로 작성된 효율 좋은 multi dimensional array 계산 기능이 있습니다.\n","\n","거기에 더해, `require_grad=True`로 설정되어 있는 tensor들에 대해서, cumulative automatic differentiation을 통한 gradient 추적 기능을 제공합니다.\n","\n","이 기능은 추후 neural network를 학습시키는 코드를 짤 때 핵심적인 기능이 됩니다.\n","\n","![image](https://drive.google.com/uc?export=download&id=1KY7DXZDwKj65vc5fm2bX_s4NACFoyH6K)\n","\n","지금은 \n","\n","- automatic differentation을 통한 gradient 추적이 어떻게 이뤄지는지 \n","- 추적이 필요하지 않을 때는 어떻게 멈출 수 있는지\n","\n","를 알아보겠습니다."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"0PoY9t8Paq65","executionInfo":{"status":"ok","timestamp":1685955475733,"user_tz":-540,"elapsed":6,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"}}},"outputs":[],"source":["import torch"]},{"cell_type":"markdown","metadata":{"id":"EmerD-bXEp5X"},"source":["one linear network를 정의합니다."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"BLhh4Mi7BOrM","executionInfo":{"status":"ok","timestamp":1685955475733,"user_tz":-540,"elapsed":6,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"}}},"outputs":[],"source":["import torch\n","\n","# Let's define a simple one layer network: f(x) = wx + b.\n","x = torch.rand(4, requires_grad=True)\n","w = torch.rand(4, requires_grad=True)\n","b = torch.rand(4, requires_grad=True)\n","\n","# Forward pass\n","z = w * x \n","z = z + b \n","z = z.mean()"]},{"cell_type":"markdown","metadata":{"id":"tFi36F-KEivG"},"source":["gradient 추적을 위해, z를 scalar로 만들어 줍니다."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"fVupsQd-EhoD","executionInfo":{"status":"ok","timestamp":1685955475733,"user_tz":-540,"elapsed":5,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"}}},"outputs":[],"source":["# New computation using z\n","q = z.detach()"]},{"cell_type":"markdown","metadata":{"id":"e9rTYLH7FIRs"},"source":["비교를 위해, tensor value 자체는 z와 같지만, gradient 추적 정보는 `.detach()` 를 사용해서 없애버린 tensor q를 선언합니다.\n","\n","z, q의 computational graph가 생각대로 처리되었는지 확인합니다."]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1685955475733,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"},"user_tz":-540},"id":"rXLidlY-B6Rt","outputId":"1f3583f1-4d2c-46c6-8b2d-0eb38bdd2c28"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dose z requires gradient information? : True\n","Dose q requires gradient information? : False\n"]}],"source":["print(\"Dose z requires gradient information? :\", z.requires_grad)\n","print(\"Dose q requires gradient information? :\", q.requires_grad)"]},{"cell_type":"markdown","metadata":{"id":"gfj2wp69Cjbf"},"source":["q 는 gradient 추적을 위한 computational graph가 없기 때문에, `.backward()` 호출을 통한 gradient backpropagation이 불가능합니다.\n","\n","`.backward()`를 하기 전에 linear network의 parameter가 gradient를 가지고 있는지 확인해보겠습니다."]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1685955475733,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"},"user_tz":-540},"id":"b1d9EZVeC3EZ","outputId":"1d311f8a-e7d8-45c4-aa5f-44bff194b72c"},"outputs":[{"output_type":"stream","name":"stdout","text":["None\n","None\n"]}],"source":["print(w.grad)  \n","print(b.grad) "]},{"cell_type":"markdown","metadata":{"id":"G0gSpHXoFww8"},"source":["아직 z에서 시작되는 gradient backpropagation을 수행하지 않아서, gradient 정보가 없는 모습입니다."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"2OgoQLY1Cri4","executionInfo":{"status":"ok","timestamp":1685955475733,"user_tz":-540,"elapsed":5,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"}}},"outputs":[],"source":["z.backward()"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1685955475733,"user":{"displayName":"Chanhui Lee","userId":"04634662997623326251"},"user_tz":-540},"id":"df10w_fwCUXH","outputId":"727290c6-9037-4011-d849-63b7ad80ef86"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.1176, 0.1427, 0.0594, 0.1226])\n","tensor([0.1176, 0.1427, 0.0594, 0.1226], grad_fn=<DivBackward0>)\n","tensor([0.2500, 0.2500, 0.2500, 0.2500])\n"]}],"source":["print(w.grad)\n","print(x / 4)  \n","print(b.grad) "]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}